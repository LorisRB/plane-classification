{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_plane.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSFcYlHCm955RfSQaqj91j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorisRB/plane-classification/blob/main/notebooks/Classification_plane.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import FGVC Aircraft database"
      ],
      "metadata": {
        "id": "kyRpO_v6IWzn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuWlA8_vHYmO",
        "outputId": "23c35f49-e23e-4fd6-e4f6-b3ad7dfa4ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0^C\n",
            "tar (child): fgvc-aircraft-2013b.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n",
            "mv: cannot stat 'fgvc-aircraft-2013b': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\n",
        "!tar xzf fgvc-aircraft-2013b.tar.gz\n",
        "!mv fgvc-aircraft-2013b dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports libraries"
      ],
      "metadata": {
        "id": "O1TbmibfIhe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# baselib \n",
        "import pathlib\n",
        "\n",
        "# imports \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import yaml\n",
        "\n",
        "#from\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "rd2MrAtEIgwT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define constants"
      ],
      "metadata": {
        "id": "PgoyRp3EJPYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with (r'config.yaml') as yaml_data:\n",
        "  params = yaml.safe_load(yaml_data)\n",
        "  params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "YK8OOytg08NI",
        "outputId": "a37ac7ca-65bc-4465-b0ba-e955c3be1edb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9ecedeca86e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mr'config.yaml'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0myaml_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaml_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: __enter__"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "manufacturer_df = pd.read_csv(DATA_DIR / 'images_manufacturer_train.txt', sep=' ',\n",
        "            names=['image_id', 'manufacturer'],\n",
        "            usecols=['image_id', 'manufacturer'], # usecols for v1.4 compatibility\n",
        "            dtype={'image_id': str},              # ids are not int but string\n",
        "           )"
      ],
      "metadata": {
        "id": "clW5gh_lJSoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries"
      ],
      "metadata": {
        "id": "0E8AFZodJsrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_image_database(path, target):\n",
        "  \"\"\"Build a pandas dataframe with target class and access path to images.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  path (Path): path pattern to read csv file containing images information.\n",
        "  target (str): name of the target column.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  A pandas dataframe, including target class and path to image.\n",
        "  \"\"\"\n",
        "  _df = pd.read_csv(path, sep='\\t',\n",
        "              names=['all'],\n",
        "              dtype={'all': str},              # ids are not int but string\n",
        "            )\n",
        "\n",
        "  # La fonction split() découpe une chaîne de caractères\n",
        "  _df['image_id'] = _df['all'].apply(lambda x: x.split(' ')[0])\n",
        "\n",
        "  # La fonction '<car>'.join(liste) concatène les éléments de liste en utilisant le séparateur <car>\n",
        "  _df[target] = _df['all'].apply(lambda x: ' '.join(x.split(' ')[1:]))\n",
        "\n",
        "  # La colonne path contient le chemin d'accès à l'image\n",
        "  _df['path'] = _df['image_id'].apply(lambda x: pathlib.Path('dataset/data/images') / (x + '.jpg'))\n",
        "\n",
        "  return _df.drop(columns=['all'])"
      ],
      "metadata": {
        "id": "DbTYg8vRJvDu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(df, row, target):\n",
        "  \"\"\"Show an image from an image database, with the associated class.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df (pd.DataFrame): images definition dataframe\n",
        "  row (int): row index in df of image to be displayed\n",
        "  target (str): name of the target column\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "  assert target in df.columns, \"Missing target column in dataframe\"\n",
        "  assert 'path' in df.columns, \"Missing image path in dataframe\"\n",
        "  print(df.iloc[row,][target])\n",
        "  plt.imshow(plt.imread(df.iloc[row,]['path']))\n",
        "  return"
      ],
      "metadata": {
        "id": "hYOoi3FxJ-SD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_resize_image(path, height, width):\n",
        "  \"\"\"Load an image and resize it to the target size.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  path (Path): access path to image file\n",
        "  height (int): resize image to this height\n",
        "  width (int): resize image to this width\n",
        "  \n",
        "  Returns\n",
        "  -------\n",
        "  np.array containing resized image\n",
        "  \"\"\"\n",
        "  return np.array(Image.open(path).resize((width, height)))\n",
        "\n"
      ],
      "metadata": {
        "id": "SsCNGlrqKKIX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_x_and_y(df: pd.DataFrame, target: str, images: str):\n",
        "  \"\"\"Build x tensor and y tensor for model fitting.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df (pd.DataFrame): dataframe containing images and target\n",
        "  target (str): name of target column\n",
        "  images (str): name of images column\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  x (np.array): tensor of x values\n",
        "  y (np.array): tensor of y values\n",
        "  \"\"\"\n",
        "  x = np.array(df[images].to_list())\n",
        "  y = tf.keras.utils.to_categorical(df[target].astype('category').cat.codes)\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "SeBS_JVwLhgz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model"
      ],
      "metadata": {
        "id": "lp1krQBoJvV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classification_model(df: pd.DataFrame, target: str, images: str):\n",
        "  \"\"\"Build a TF model using information from target and images columns in dataframe.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df (pd.DataFrame): dataframe with target and images columns\n",
        "  target (str): column name for target variable\n",
        "  images (str): column name for images\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  TF model built & compiled\n",
        "  \"\"\"\n",
        "  nb_classes = df[target].nunique() # Compute number of classes for output layer\n",
        "  size = df[images].iloc[0].shape # Compute images size for input layer\n",
        "\n",
        "  #Building the model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=size))\n",
        "  model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  model.add(Dense(nb_classes, activation='softmax')) # output layer with nb_classes\n",
        "\n",
        "  #Compilation of the model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "13mAfp7vJxw7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of images"
      ],
      "metadata": {
        "id": "HmAizmZeL4yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_images(images, model, classes_names=None):\n",
        "  \"\"\"Classify images through a TF model.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  images (np.array): set of images to classify\n",
        "  model (tf.keras.Model): TF/Keras model\n",
        "  classes_names: dictionary with names of classes\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  predicted classes\n",
        "  \"\"\"\n",
        "\n",
        "  results = model.predict(images) # predict for images\n",
        "  classes = np.argmax(results, axis=1) # argmax returns the index of the max value per row\n",
        "  if classes_names is not None:\n",
        "    classes = np.array(classes_names[classes])\n",
        "  return classes"
      ],
      "metadata": {
        "id": "Pw2qOgPgL108"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the model"
      ],
      "metadata": {
        "id": "KZ6pj8zIND_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, basename):\n",
        "  \"\"\"Save tf/Keras model.\n",
        "\n",
        "  Model file is named model + timestamp.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model (tf/Keras model): model to be saved\n",
        "  basename: location to save model file\n",
        "  \"\"\"\n",
        "  model.save('{}_{}.h5'.format(basename, datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')))\n",
        "  return"
      ],
      "metadata": {
        "id": "UAdnLA6eNB55"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation of the TPU"
      ],
      "metadata": {
        "id": "PDYqjQc9M3y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "metadata": {
        "id": "JufyaNPcM-pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "zw_kLHMhNQ1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utiliser fonctions preliminaires"
      ],
      "metadata": {
        "id": "1QTrzDYiNzsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "  model = build_classification_model(train_df, 'manufacturer', 'resized_image')\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "foVrhwRENS9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}